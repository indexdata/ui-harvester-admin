{
    "meta.title": "Harvester admin",
    "no-value": "-",
    "error": "Something went wrong",
    "resultCount": "{count, number} {count, plural, one {record found} other {records found}}",
    "add": "Add",
    "actions.new": "Nowy rekord",
    "actions.new.harvestable.oaiPmh": "OAI-PMH harvestable",
    "actions.new.harvestable.xmlBulk": "XML bulk harvestable",
    "actions.new.harvestable.connector": "Connector harvestable",
    "actions.new.harvestable.status": "Status-report harvestable",
    "nav.harvestables": "Harvestables",
    "button.edit": "Edytuj",
    "button.delete": "Usuń",
    "button.start-job": "Start job",
    "button.stop-job": "Stop job",
    "button.confirm": "Confirm",
    "op.delete.confirm": "Are you sure you want to delete this record?",
    "op.delete.completed": "Record <b>{name}</b> deleted",
    "op.run.completed": "Job <b>{name}</b> started",
    "op.stop.completed": "Job <b>{name}</b> stopped",
    "harvestables.column.name": "Nazwa",
    "harvestables.column.currentStatus": "Status",
    "harvestables.column.lastHarvestFinished": "Last harvest finished",
    "harvestables.column.enabled": "Enabled?",
    "harvestables.column.jobClass": "Job class",
    "harvestables.column.id": "ID",
    "harvestables.column.message": "Message (processed/loaded/deleted(skipped)/failed)",
    "harvestables.column.enabled.true": "Tak",
    "harvestables.column.enabled.false": "Nie",
    "harvestables.column.jobClass.OaiPmhResource": "Protokół OAI-PMH",
    "harvestables.column.jobClass.XmlBulkResource": "XML bulk",
    "harvestables.column.jobClass.HarvestConnectorResource": "Harvest connector",
    "harvestables.column.jobClass.StatusResource": "Status report",
    "harvestables.column.currentStatus.NEW": "Nowy",
    "harvestables.column.currentStatus.OK": "OK",
    "harvestables.column.currentStatus.WARN": "Warning",
    "harvestables.column.currentStatus.ERROR": "Błąd",
    "harvestables.column.currentStatus.RUNNING": "Running",
    "harvestables.column.currentStatus.FINISHED": "Finished",
    "harvestables.column.currentStatus.KILLED": "Killed",
    "harvestables.index.name": "Nazwa",
    "harvestables.index.id": "ID",
    "harvestables.index.message": "Wiadomość",
    "searchInputLabel": "XXX searchInputLabel",
    "accordion.devinfo": "Developer information",
    "harvestables.heading.general": "Informacja ogólna",
    "harvestables.field.id": "Id",
    "harvestables.field.id.help": "Automatically assigned identifier for the job",
    "harvestables.field.name": "Nazwa",
    "harvestables.field.name.help": "Preferably a unique name for users to identify this Harvester resource. In some cases the name may be proposed after filling out protocol specific section of the configuration (e.g Index Data Connectors, OAI-PMH).",
    "harvestables.field.serviceProvider": "Service provider",
    "harvestables.field.serviceProvider.help": "Free-text field used by support staff for recording administrative information. Not used by the harvester.",
    "harvestables.field.usedBy": "Used by",
    "harvestables.field.usedBy.help": "Free-text field for tagging a job with the intended target audience, like a user group or customer of the resource. Multiple user/customer tags may be separated by commas. The tags can be used for filtering status reports by usages/customers.",
    "harvestables.field.managedBy": "Managed by",
    "harvestables.field.managedBy.help": "Free-text field for tagging a job with the producer or manager of the resource. Multiple tags may be separated by commas. The tags can be used for filtering status reports by job administrators.",
    "harvestables.field.openAccess": "Open access resource?",
    "harvestables.field.description": "Opis treści",
    "harvestables.field.description.help": "Free-text field used by support staff for recording administrative information. Not used by the harvester.",
    "harvestables.field.technicalNotes": "Technical notes",
    "harvestables.field.technicalNotes.help": "Free-text field used by support staff for recording administrative information. Not used by the harvester.",
    "harvestables.field.contactNotes": "Contact notes",
    "harvestables.field.contactNotes.help": "Free-text field used by support staff for recording administrative information. Not used by the harvester.",
    "harvestables.field.enabled": "Harvest job enabled?",
    "harvestables.field.enabled.help": "Check to run the Harvesting job as described by the time/interval selected in \"Harvest schedule\". Leaving this box unchecked will make the job inactive.",
    "harvestables.field.scheduleString": "Harvest schedule",
    "harvestables.field.scheduleString.help": "Use these fields to define a recurring time/interval at which the Harvester job should run. E.g for weekly runs specify a day of the week on which the harvest should be executed.",
    "harvestables.field.scheduleString.harvest": "Harvest",
    "harvestables.field.scheduleString.day": "(day) of",
    "harvestables.field.scheduleString.month": "(month) if it's",
    "harvestables.field.scheduleString.weekday": "(dzień tygodnia)",
    "harvestables.field.scheduleString.time": "Harvesting time",
    "harvestables.field.scheduleString.hour": "(hour in 24 format)",
    "harvestables.field.scheduleString.minute": "(min)",
    "harvestables.field.transformationPipeline": "Transformation pipeline",
    "harvestables.field.transformationPipeline.help": "Select the transformation required to match the input format delivered by the feed to the internal format used by the Harvester for data storage. See the Transformation Pipelines manual section for more details.",
    "harvestables.field.laxParsing": "Use lax parsing (if possible)",
    "harvestables.field.laxParsing.help": "When enabled, harvester will attempt to parse malformed XML (missing closing tags, entities)",
    "harvestables.field.encoding": "Encoding override (ISO-8859-1, UTF-8, ...)",
    "harvestables.field.encoding.help": "A feed can return invalid encoded responses, such as having an XML header with encoding set to UTF-8, but actually return ISO-8859-1 in the data. Setting this field to the actual encoding will force the Harvester to use the specified encoding.",
    "harvestables.field.storage.name": "Magazyn",
    "harvestables.field.storage.name.help": "Select the storage type and location for the harvested data. The Harvester has a storage abstraction layer to allow it to work with multiple potential record storage systems, but at present, only Solr/Lucene is supported. Once the Storage has been selected, it is possible to view the indexed records by clicking the Stored records: click to view field.",
    "harvestables.field.storageBatchLimit": "Storage batch limit",
    "harvestables.field.cacheEnabled": "Cache on disk?",
    "harvestables.field.cacheEnabled.help": "If enabled, harvest data is kept in the filesystem cache and the job can be restarted from this cache without needing to go back to the server.",
    "harvestables.field.storeOriginal": "Store original record content?",
    "harvestables.field.recordLimit": "Ogranicz liczbę rekordów do",
    "harvestables.field.recordLimit.help": "Limit the harvest run to a specified number of records: useful for testing job settings and transformation pipelines.",
    "harvestables.field.timeout": "Connection/read timeout (seconds)",
    "harvestables.field.timeout.help": "Specify a non-default timeout value for obtaining and reading from the network connection (socket). Values under 1 minute are not recommended.",
    "harvestables.field.logLevel": "Log level",
    "harvestables.field.logLevel.help": "Specify the logging level for the job with DEBUG being the most verbose. INFO is the recommended log level in most cases.",
    "harvestables.field.failedRecordsLogging": "Saving failed records",
    "harvestables.field.failedRecordsLogging.help": "Specify whether or not failed records should be saved as XML files in a designated log directory. Also specify retention policy for the directory, that is, whether to retain files that were saved in previous runs and, if so, whether to overwrite an existing file if the same record fails again or rather add a sequence number to the new file name in order not to overwrite.",
    "harvestables.field.maxSavedFailedRecordsPerRun": "Maximum number of failed records saved next run",
    "harvestables.field.maxSavedFailedRecordsPerRun.help": "Sets a maximum number of files to save in the failed records directory per run. The job log will tell when the limit is reached.",
    "harvestables.field.maxSavedFailedRecordsTotal": "Maximum number of failed records saved total",
    "harvestables.field.maxSavedFailedRecordsTotal.help": "Sets a maximum number of files to be saved in the failed records directory at any given time - as the sum of previously saved records (that were not cleaned up before this run) plus any new records added during the run. The job log will tell when the limit is reached.",
    "harvestables.field.mailAddress": "Notification e-mail addresses",
    "harvestables.field.mailAddresses": "Notification e-mail addresses",
    "harvestables.field.mailAddresses.help": "List of e-mail addresses that should receive notification on job completion.",
    "harvestables.field.mailLevel": "Send notification if severity at least",
    "harvestables.field.mailLevel.help": "specify job completion status with the least severity that will trigger the e-mail notification.",
    "harvestables.field.constantFields": "List of constant fields",
    "harvestables.field.constantFields.help": "A list of NAME=VALUE pairs. For a harvestable that has this field set, each harvested record has each NAME field set to the corresponding VALUE.",
    "harvestables.field.json": "Extra configuration: (JSON)",
    "harvestables.field.json.help": "Specify additional advanced harvester configuration in the JSON format.",
    "harvestables.field.type.oaiPmh": "OAI-PMH specific information",
    "harvestables.field.url": "URL repozytorium OAI",
    "harvestables.field.url.help": "Enter a link (http-based) to the resource to be harvested. Include the base link defined by OAI Set Name: (see below). Some resources have multiple sets within the repository. If no specific set is identified by the URL, the full repository will be harvested.",
    "harvestables.field.oaiSetName": "OAI set name (type for suggestions)",
    "harvestables.field.oaiSetName.help": "an optional setting, an OAI-PMH setSpec value which specifies set criteria for selective harvesting.",
    "harvestables.field.metadataPrefix": "Metadata prefix",
    "harvestables.field.metadataPrefix.help": "A string that specifies the metadata format in OAI-PMH requests issued to a targeted repository. It is important to choose the correct format or no data will be harvested from the repository. Make sure a Transformation Pipeline that matches the metadata format used in the repository is selected, otherwise records will not be understood by the Harvester. Repositories generally use one of the following prefixes (or embedded data formats): Dublin Core (OAI-DC) or MARC XML (MARC12/USMARC). Other less common MetadataPrefix values include PMC (PubMed Central full-text records), PMC (PubMed Central metadata records), and PZ2 (pazpar2).",
    "harvestables.field.dateFormat": "Date format",
    "harvestables.field.useLongDateFormat": "Use long date format",
    "harvestables.field.useLongDateFormat.help": "Check-box to indicate whether to use a long date format when requesting records from the OAI-PMH resource. This is not used very often, but is required by some resources.",
    "harvestables.field.fromDate": "Harvest from",
    "harvestables.field.fromDate.help": "If empty and no resumption token is set, the Harvester will harvest the full data set from the resource. When this field contains a value, upon completion of the job the Harvester will reset the value of this field to the day prior to the current run date, so subsequent runs will harvest only new records.",
    "harvestables.field.untilDate": "Harvest until",
    "harvestables.field.untilDate.help": "Upper date limit for selective harvesting. On consecutive runs the Harvester will clear this field making the date interval open-ended.",
    "harvestables.field.resumptionToken": "Resumption token (overrrides date)",
    "harvestables.field.resumptionToken.help": "The OAI-PMH protocol supports splitting bigger datasets into smaller chunks. On delivery of a chunk of records, the OAI-PMH returns a token which the next request should use in order to get the next chunk. If an OAI-PMH job halts before completion, the resumption token will be set in this field. Sometimes it is possible to run it again from this resumption point at a later stage, but this is not always supported.",
    "harvestables.field.clearRtOnError": "Clear resumption token on connection errors",
    "harvestables.field.clearRtOnError.help": "Clear the resumption token for harvests that complete in an error state. This is useful when server errors out and the last resumption token is no longer valid.",
    "harvestables.field.keepPartial": "Keep partial harvests",
    "harvestables.field.keepPartial.help": "When checked, partial records harvested during a failed harvest run will be retained in storage.",
    "harvestables.field.retryCount": "Request retry count",
    "harvestables.field.retryCount.help": "Specify how many times the harvester should retry failed harvest requests, 0 disables retrying entirely.",
    "harvestables.field.retryWait": "Delay before retry (seconds)",
    "harvestables.field.retryWait.help": "Delay for retrying failed requests. Only change when resource fails to work with the default values.",
    "harvestables.field.type.xmlBulk": "XML bulk specific information",
    "harvestables.field.urls": "URLs",
    "harvestables.field.urls.help": "One or more space-separated URL (HTTP or FTP) for XML  or MARC binary data. Jump or index pages (HTML pages with URLs) are supported and  so are FTP directories. For FTP, harvesting of recursive directories may be enabled below.",
    "harvestables.field.allowErrors": "Continue on errors?",
    "harvestables.field.allowErrors.help": "Check to continue harvesting and storing records even if  retrieving some of the listed resources fails.",
    "harvestables.field.overwrite": "Overwrite data with each run (non-incremental)?",
    "harvestables.field.overwrite.help": "Check to delete all previously  harvested data before beginning the next scheduled (or manually triggered) run. This  may be used when complete catalog dumps reside on the server.    With FOLIO Inventory Storage there is no deletion of all previously harvested data, and checking  this option instead indicates that existing records should be overlaid.",
    "harvestables.field.allowCondReq": "Ask server for new files only (incremental)?",
    "harvestables.field.allowCondReq.help": "Ask the server if the files are  modified before attempting a harvest, relies on proper timestamp handling on the  server side. It’s usually safe to have this enabled as servers are eager to  update the modification date, even in cases when the files themselves don’t  change. Enabling this setting may significantly shorten harvest times.",
    "harvestables.field.initialFromDate": "Initial from date (if incremental)",
    "harvestables.field.initialFromDate.help": "Allows to specify the initial from  harvest date when <strong>ask server for new files only</strong> option is checked. When filled out, only files newer than the specified date will be harvested.    With FOLIO Inventory Storage, the setting additionally indicates that only incoming records  that were updated on or after this date should be loaded. Additionally, for this to take effect,  the incoming records must provide a 'lastUpdated' in the element 'processing' and on the format YYYY-MM-DD &lt;processing&gt; &lt;lastUpdated&gt;1970-01-01&lt;/lastUpdated&gt; &lt;/processing&gt; By default the logic would filter by the finishing date of the last harvest, so setting  'Initial from date' overrides the default behavior.   Following rules thus applies:   <li>If 'Overwrite data' is checked, all records are loaded.</li>  Otherwise:   <li>If the incoming records provide a 'lastUpdated' date, and the 'Initial from date' is set,  then only records updated at or after that date will be loaded (this is regardless of  whether 'Ask server for new files only (incremental)' is checked or not)</li> <li>If the incoming records provide a 'lastUpdated' date, and the 'Initial from date' is NOT set,  then only records updated at or after the last harvest date will be loaded</li>   But   <li>Any record without a 'lastUpdated' date will be loaded</li>",
    "harvestables.field.splitAt": "Split XML at depth (zero/empty disables split)",
    "harvestables.field.splitAt.help": "For XML data. This should  usually be set to 1 for XML feeds, if we want to harvest the record elements in  the data structured like:   &lt;root&gt; &nbsp;&lt;record/&gt; &nbsp;&lt;record/&gt; &lt;/root&gt;",
    "harvestables.field.splitSize": "Split files at number of records (zero/empty disables split)",
    "harvestables.field.splitSize.help": "The Harvester  tries to imply streaming parsing where possible, but many XSL Transformations  will not support this. Attempting to transform millions of records will be too  memory consuming, so breaking the resource into chunks of 1000 records seems to  be a reasonable option. Enter into this field the number of records to be  contained in each chunk.",
    "harvestables.field.expectedSchema": "Mime-type override (e.g: application/marc; charset=MARC-8)",
    "harvestables.field.expectedSchema.help": "The Harvester detects  the type (XML vs MARC binary) from the MIME-type and file extension. It is also able  to deal with compressed archives (zip, tar, gzip), in some rare case it may be  required to provide the content type manually (e.g if it’s missing or wrong),  the format is:   MIME-type [; optional character encoding].",
    "harvestables.field.outputSchema": "MARC XML transformation format (application/marc or application/tmarc)",
    "harvestables.field.outputSchema.help": "This field  expresses the output format of binary MARC reading–which will also be the input  format for the transformation pipeline. If the Transformation Pipeline expects MARC21  XML, this should be set to Application/marc. If the pipeline expects Turbo MARC XML,  it should be set to Application/tmarc.",
    "harvestables.field.recurse": "Recurse into subfolders?",
    "harvestables.field.recurse.help": "When set, the harvester will traverse the entire directory  tree and search for harvestable files. This setting should be enabled with care.",
    "harvestables.field.includeFilePattern": "Dołącz pliki (wyrażenie regularne)",
    "harvestables.field.includeFilePattern.help": "This setting can be used to filter what files  to harvest.  The filter applies to files in FTP directories as well as in archives (ZIP/tar).  When set to a regular expression, the harvester  will only harvest files with names matching the regular expression (unless the file name is  at the same time excluded by an exclude pattern).   Example:  <pre>.*\\.xml|.*\\.marc</pre>  Would include only .xml and .marc files.    Note that file name dots must be escaped.    Note that ZIP and tar files (.zip,.gz,.tar) are loaded even if they are not specified in the  include pattern. To enforce exclusion of ZIP or tar files they would have to be specified in  an exclude pattern (see help text for that).",
    "harvestables.field.excludeFilePattern": "Wyklucz pliki (wyrażenie regularne)",
    "harvestables.field.excludeFilePattern.help": "This setting can be used to filter what files to harvest. The filter applies to files in FTP directories as well as entries in archives (ZIP/tar).  When set to a regular expression, the harvester  will skip any file with a file name matching the expression. Example: <pre>readme\\.txt|README|.*\\.jpg|.*\\.gif</pre>  Would exclude files with names readme.txt, README as well as .jpg and .gif files  from FTP directories or ZIP/tar archives.",
    "harvestables.field.passiveMode": "Use passive mode for FTP transfers?",
    "harvestables.field.passiveMode.help": "When set passive, instead of active, mode is  used for FTP connections. If harvester is running within a restricted firewall that  blocks FTP active mode connections, enabling this setting might help. It might be,  however, necessary to align this mode with what FTP server expects.",
    "harvestables.field.csvConfiguration": "CSV parser configuration",
    "harvestables.field.csvConfiguration.help": "The harvester will detect (either by MIME-type or by file extension)  and attempt to parse CSV (comma separated values) files into an XML representation for further processing. The XML representation of each  data row looks as follows: <pre>&lt;row&gt;&lt;field name=&quot;column name or number&quot;&gt;field value&lt;/field&gt;...&lt;/row&gt;</pre>  Unless the split at depth option is set to > 0, all rows will be parsed into a single XML document and wrapped with an additional &lt;rows&gt; root element. For large CSV files it may be a good idea to set the split at depth to 1.  The parser configuration is expressed in a semicolon delimited key/value list, like so: key1=value1; key2=value2. List of supported options is as follows: <ul> <li> charset: default \"iso-8859-1\", specifies the character encoding of the files</li> <li> delimiter: default \",\" for CSV and \"\\t\" for TSV, specifies the field delimiter used in the files</li> <li> containsHeader: default \"yes\", specifies if the first line in the files contains the header line</li> <li> headerLine: no default, allows to override or specify headers, format is a comma-separated list e.g headers=\"title,author,description\"</li></ul>",
    "harvestables.field.type.connector": "Connector specific information",
    "harvestables.field.connectorEngineUrlSetting.label": "CF Engine",
    "harvestables.field.connectorEngineUrlSetting.label.help": "Select the Connector Engine instance that will be used to execute  the Connector harvesting job. The default engine is hosted by Index Data but may be  also installed locally on the customer site. Additional Connector Engines can be  specified through the Settings tab.",
    "harvestables.field.engineParameters": "Engine parameters (optional)",
    "harvestables.field.engineParameters.help": "Additional or custom values of Connector Engine  session parameters used by this job. See CFWS manpage for more information.",
    "harvestables.field.connectorRepoUrlSetting.label": "CF Repository",
    "harvestables.field.connectorRepoUrlSetting.label.help": "Select the connector repository where the Connectors are hosted  and maintained. Usually, the Connector Repository is provided by Index Data and may  require a login account. The account credentials are provided directly in the  Connector Repository URL setting accessed from the Settings tab and should have the  form: <pre>http(s)://&lt;repouser&gt;:&lt;repopass&gt;@url.to.the.repository</pre>.",
    "harvestables.field.connector": "Connector (type for suggestion)",
    "harvestables.field.connector.help": "Enter here the name of the harvesting  connector specific to the harvested resource. This field provides suggestions by  looking up the Repository so only a couple of initial characters or a part of the  name is required.",
    "harvestables.field.overwrite-connector.help": "Check to delete all previously  harvested data before beginning the next scheduled (or manually triggered) run.",
    "harvestables.field.connuser": "Nazwa użytkownik",
    "harvestables.field.connuser.help": "User name required for access to a harvested resource that  requires authentication.",
    "harvestables.field.password": "Hasło",
    "harvestables.field.password.help": "Password required for access to a harvested resource that requires  authentication.",
    "harvestables.field.proxy": "Proxy server address",
    "harvestables.field.proxy.help": "Address of the proxy server that should be used by the  harvesting engine, e.g to deal with cases when the resource is IP authenticated.",
    "harvestables.field.initData": "Init Data",
    "harvestables.field.initData.help": "Advanced setting to provide additional initialization parameters  to the harvesting connector. Any username/password/proxy specified in the inputs  above will take precedence over settings specified in this field. These settings  must be provided in JSON format.",
    "harvestables.field.startToken": "Start token (incremental harvest)",
    "harvestables.field.startToken.help": "The use of a start token for incremental  harvesting is connector specific and depends on the connector capability. This setting  must be provided in JSON format.",
    "harvestables.field.sleep": "Delay between requests (milliseconds)",
    "harvestables.field.sleep.help": "Delay between requests made from the  harvester to the connector engine. Use when the resource is sensitive to high loads.",
    "harvestables.field.failedRetryCount": "Failed request retry count",
    "harvestables.field.failedRetryCount.help": "Specify how many times the harvester should retry  failed harvest requests, 0 disables retrying entirely.",
    "harvestables.field.type.status": "Informacja ogólna",
    "harvestables.field.usageTags": "Filter: list of usage tags",
    "harvestables.field.usageTags.help": "Used for filtering the status report by the user groups on customers tagged to a harvest job (\"Used by\").",
    "harvestables.field.adminTags": "Filter: list of admin tags",
    "harvestables.field.adminTags.help": "Used for filtering the status report by the harvestables creator or administrator, as tagged to the harvest job (\"Managed by\")",
    "harvestables.field.statusJobEnabled": "Status job enabled",
    "harvestables.field.customMailAddresses": "Custom e-mails addresses (multiple separated with comma)",
    "harvestables.heading.status": "Status information",
    "harvestables.field.currentStatus": "Aktualny status:",
    "harvestables.field.initiallyHarvested": "Initial harvest",
    "harvestables.field.lastHarvestStarted": "Last harvest started",
    "harvestables.field.lastHarvestFinished": "Last harvest completed",
    "harvestables.field.lastUpdated": "Last updated",
    "harvestables.field.message": "Message from last harvest:",
    "harvestables.field.failedRecordsLogging.NO_STORE": "Nie zapisuj niepoprawnych rekordów",
    "harvestables.field.failedRecordsLogging.CLEAN_DIRECTORY": "Do save. Clean up directory first",
    "harvestables.field.failedRecordsLogging.CREATE_OVERWRITE": "Zapisz. Nadpisz istniejące pliki",
    "harvestables.field.failedRecordsLogging.ADD_ALL": "Zapisz. Dodaj numerowane wersje istniejących plików",
    "SENTINEL": "SENTINEL",
    "harvestables.field.jobClass": "Job class",
    "harvestables.field.jobClass.oaiPmh": "Protokół OAI-PMH",
    "harvestables.field.jobClass.xmlBulk": "XML bulk",
    "harvestables.field.jobClass.connector": "Harvest connector",
    "harvestables.field.jobClass.status": "Status report",
    "harvestables.column.currentStatus.SHUTDOWN": "Shutdown",
    "button.view-log": "View log",
    "summary-table.summary": "Podsumowanie",
    "summary-table.instances": "Instancja",
    "summary-table.holdings": "Zasoby",
    "summary-table.items": "Egzemplarz",
    "summary-label.processed": "Processed",
    "summary-label.loaded": "Loaded",
    "summary-label.deleted": "Deleted(skipped)",
    "summary-label.failed": "Niepowodzenie",
    "failed-records.recordNumber": "Record number",
    "failed-records.timeStamp": "Time stamp",
    "failed-records.instanceHrid": "HRID instancji",
    "failed-records.instanceTitle": "Instance title",
    "failed-records.errors": "Errors",
    "harvestables.column.logFile": "Plik log",
    "harvestables.column.records": "Rekordy",
    "logs.countFailedRecords": "{count, number} {count, plural, one {failed record} other {failed records}}",
    "stats.instances": "Instancje",
    "stats.holdings": "Zasoby",
    "stats.items": "Egzemplarze",
    "nav.jobs": "Jobs",
    "nav.jobs-for": "Jobs for {name}",
    "button.old-jobs": "Old jobs",
    "logs.plainTextLog.running": "Live plain text log for current running job",
    "logs.plainTextLog.previous": "Plain text log for last job",
    "logs.plainTextLog.refresh": "Refresh",
    "settings.storage": "Storage engines",
    "settings.pipeline": "Transformation pipelines",
    "settings.step": "Transformation steps",
    "permission.all": "Harvester admin: All permissions",
    "filter.date.started": "Date started",
    "filter.date.started.from": "From",
    "filter.date.started.to": "To",
    "filter.date.finished": "Date finished",
    "filter.date.finished.from": "From",
    "filter.date.finished.to": "To",
    "error.invalidSort.label": "Invalid sort criterion",
    "error.invalidSort.content": "It is not possible to sort on the <code>{name}</code> column due to implementation limitations.",
    "jobs.index.name": "Nazwa",
    "jobs.index.id": "ID",
    "jobs.index.harvestableId": "Harvestable ID",
    "jobs.index.message": "Wiadomość",
    "jobs.index.all": "(Wszystko)",
    "jobs.column.name": "Harvestable name",
    "jobs.column.status": "Status",
    "jobs.column.amountHarvested": "Records",
    "jobs.column.seconds": "Seconds",
    "jobs.column.started": "Started",
    "jobs.column.finished": "Finished",
    "jobs.column.type": "Job class",
    "jobs.column.message": "Message (processed/loaded/deleted(skipped)/failed)",
    "nav.records": "Failed records",
    "records.index.recordNumber": "Record number",
    "records.index.instanceHrid": "Instance hrid",
    "records.index.instanceTitle": "Instance title",
    "records.index.errors": "Errors",
    "records.index.timeStamp": "Time stamp",
    "records.index.harvestableName": "Harvestable name",
    "records.index.all": "(Wszystko)",
    "filter.date.timeStamp": "Time stamp",
    "filter.date.timeStamp.from": "From",
    "filter.date.timeStamp.to": "To",
    "failed-records.harvestableName": "Harvestable name",
    "button.view-log.current": "Current log",
    "button.view-log.last": "Last log",
    "harvestables.column.oldJobs": "Old jobs",
    "selectValue": "Wybierz wartość",
    "fillIn": "Please fill this in to continue",
    "selectToContinue": "Proszę wybrać, aby kontynuować",
    "filter.numeric.records": "Records",
    "filter.numeric.records.from": "At least",
    "filter.numeric.records.to": "No more than",
    "settings.storage.heading": "Manage storage engines",
    "settings.pipeline.heading": "Manage transformation pipelines",
    "settings.step.heading": "Manage transformation steps",
    "storage.field.name": "Nazwa",
    "storage.field.description": "Opis",
    "storage.field.enabled": "Enabled",
    "storage.field.url": "URL",
    "storage.field.json": "JSON configuration",
    "storage.field.type": "Storage type:",
    "invalidJSON": "Invalid JSON: {error}",
    "op.run.error": "Could not start job <b>{name}</b>: {error}",
    "op.stop.error": "Could not stop job <b>{name}</b>: {error}",
    "logs.plainTextLog.download": "Download",
    "pipeline.field.name": "Nazwa",
    "pipeline.field.description": "Opis",
    "pipeline.field.enabled": "Enabled",
    "pipeline.field.parallel": "Równoległy",
    "pipeline.field.stepAssociations": "Transformation steps",
    "pipeline.steps.position": "#",
    "pipeline.steps.name": "Nazwa",
    "pipeline.steps.in": "In",
    "pipeline.steps.out": "Out",
    "pipeline.steps.actions": "Akcje",
    "step.field.name": "Nazwa",
    "step.field.description": "Opis",
    "step.field.enabled": "Enabled (This is unused)",
    "step.field.type": "Rodzaj",
    "step.field.inputFormat": "Input format",
    "step.field.outputFormat": "Format wyjściowy",
    "step.field.script": "Script",
    "step.field.testData": "Test data",
    "step.field.testOutput": "Test output",
    "step.field.customClass": "Custom class",
    "harvestables.field.statusJobEnabled.help": "Pusty",
    "harvestables.field.customMailAddresses.help": "Pusty",
    "set-to-xml2json": "Wybierz format XML do formatu JSON",
    "export-csv": "Eksport CSV",
    "invalidXML": "Invalid XML: {error}",
    "invalidXSLT": "Valid XML, but not an XSLT stylesheet",
    "validXSLT": "Valid XSLT stylesheet",
    "reports": "Reports",
    "transform": "Transform",
    "nav.mike": "Mike"
}